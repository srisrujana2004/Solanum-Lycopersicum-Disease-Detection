{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaQ5EFqbJSd-"
      },
      "source": [
        "## Import the required libraries and dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvCBOQJH9zyx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R-uVaoE-Ixa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0K3FGedJSeA"
      },
      "source": [
        "## Load the dataset for use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAlfEdBrIpgC"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/train',\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='categorical')\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory('/content/drive/MyDrive/validation',\n",
        "                                                  target_size=(224, 224),\n",
        "                                                  batch_size=32,\n",
        "                                                  class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oGmpprWAKyB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Print the class labels in the train generator\n",
        "print(\"Class labels in the train generator:\")\n",
        "print(train_generator.class_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA8SeWNxAAHQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Print the class labels in the test generator\n",
        "print(\"Class labels in the test generator:\")\n",
        "print(valid_generator.class_indices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgzkSdCUJSeG"
      },
      "source": [
        "## Build an AlexNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4VdrIT6NpsX"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(layers.Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
        "model.add(layers.Conv2D(256, (5, 5), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
        "model.add(layers.Conv2D(384, (3, 3), activation='relu'))\n",
        "model.add(layers.Conv2D(384, (3, 3), activation='relu'))\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
        "\n",
        "# Flatten layer\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(11, activation='softmax'))  # 11 classes\n",
        "target_size=(224, 224)\n",
        "print(train_generator.image_shape)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8VKEFVGJSeH"
      },
      "source": [
        "## Compile the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLozp_9QKL3b"
      },
      "outputs": [],
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z72i4KkOaMwB"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP7xCFuTidrZ"
      },
      "outputs": [],
      "source": [
        "history=model.fit(train_generator,\n",
        "          epochs=10,   #number of epochs\n",
        "          validation_data=valid_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N4jdF-xJSeI"
      },
      "source": [
        "## Calculate model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOl2nyaUd9yw"
      },
      "outputs": [],
      "source": [
        "accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f'Test Accuracy: {accuracy*100:.4f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB15THWHJSeI"
      },
      "source": [
        "## Save the model to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcM99pZ7CE-T"
      },
      "outputs": [],
      "source": [
        "print(\"[INFO] Saving model...\")\n",
        "model.save(\"epic model.h5\")\n",
        "print(\"[INFO] Saved model to disk!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB36ES_tJSeH"
      },
      "source": [
        "## Plot the accuracy and loss curves.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation loss and accuracy curves\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# Plot the smoothed training loss\n",
        "axs[0].plot(train_loss, label='Training Loss')\n",
        "axs[0].plot(val_loss, label='Validation Loss')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('Loss')\n",
        "axs[0].legend()\n",
        "\n",
        "# Plot the smoothed training accuracy\n",
        "axs[1].plot(train_acc, label='Training Accuracy')\n",
        "axs[1].plot(val_acc, label='Validation Accuracy')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('Accuracy')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1qQfi5LRHI0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0kzRNqiRgNh"
      },
      "source": [
        "## Test the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZn93guu801u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "# Load the saved model\n",
        "model = tf.keras.models.load_model('model.h5')\n",
        "\n",
        "# Load and preprocess a test image\n",
        "test_image_path = 'image.jpeg'\n",
        "# Load the image\n",
        "img = Image.open(test_image_path)\n",
        "# Display the image using matplotlib\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()\n",
        "test_image = image.load_img(test_image_path, target_size=(224, 224))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "test_image /= 255.0  # Normalize the pixel values\n",
        "\n",
        "\n",
        "class_name_dict = {\n",
        "    0: 'Bacterial spot',\n",
        "    1: 'Early blight',\n",
        "    2: 'Fusarium wilt',\n",
        "    3: 'Late blight',\n",
        "    4: 'Leaf mold',\n",
        "    5: 'Septoria leaf spot',\n",
        "    6: 'Spider mites',\n",
        "    7: 'Target spot',\n",
        "    8: 'Yellow leaf curl virus',\n",
        "    9: 'Mosaic virus',\n",
        "    10: 'Healthy'\n",
        "}\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(test_image)\n",
        "predicted_class = np.argmax(predictions)\n",
        "predicted_class_name = class_name_dict[predicted_class]\n",
        "\n",
        "# Display the predicted class name\n",
        "print(f\"Predicted Class: {predicted_class_name}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
